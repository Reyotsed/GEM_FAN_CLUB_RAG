# main.py
import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# å¯¼å…¥LangChainå’Œæ™ºè°±AIçš„ç›¸å…³æ¨¡å—
from langchain_community.chat_models.zhipuai import ChatZhipuAI
from langchain_community.embeddings.zhipuai import ZhipuAIEmbeddings
from langchain_chroma import Chroma  # ä½¿ç”¨æ–°çš„åŒ…
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

# --- 1. é…ç½® ---
# å¼ºçƒˆå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æ¥è®¾ç½®API Keyï¼Œè¿™æ ·æ›´å®‰å…¨
# ä½ å¯ä»¥åœ¨ç»ˆç«¯ä¸­è¿è¡Œ: export ZHIPUAI_API_KEY="ä½ çš„Key"
# æˆ–è€…ç›´æ¥åœ¨è¿™é‡Œå–æ¶ˆæ³¨é‡Šå¹¶å¡«å…¥ä½ çš„Key
# os.environ["ZHIPUAI_API_KEY"] = "****************************************"
os.environ["ZHIPUAI_API_KEY"] = "dda587eac5c949b7b7a8ecc44399ffcd.sACsHiKmuKgFeU5I" 
# æ£€æŸ¥API Keyæ˜¯å¦å·²è®¾ç½®
if "ZHIPUAI_API_KEY" not in os.environ:
    raise ValueError("é”™è¯¯ï¼šè¯·è®¾ç½® ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡ã€‚")

# å‘é‡æ•°æ®åº“çš„å­˜å‚¨è·¯å¾„ (å¿…é¡»ä¸indexing.pyä¸­ä½¿ç”¨çš„è·¯å¾„ä¸€è‡´)
CHROMA_PATH = "./chroma_db_zhipu"
if not os.path.exists(CHROMA_PATH):
    raise FileNotFoundError(f"é”™è¯¯ï¼šå‘é‡æ•°æ®åº“è·¯å¾„ '{CHROMA_PATH}' ä¸å­˜åœ¨ã€‚è¯·å…ˆè¿è¡Œindexing.pyè„šæœ¬æ¥åˆ›å»ºæ•°æ®åº“ã€‚")


# --- 2. åˆå§‹åŒ–FastAPIåº”ç”¨ ---
app = FastAPI(
    title="G.E.M. AI Chat API",
    description="ä¸€ä¸ªç”±æ™ºè°±AIé©±åŠ¨ã€æ¨¡ä»¿é‚“ç´«æ£‹è¯­æ°”çš„RAGèŠå¤©æœºå™¨äººAPI"
)

# --- 3. è®¾ç½®CORSè·¨åŸŸä¸­é—´ä»¶ ---
# è¿™å…è®¸ä½ çš„Vueå‰ç«¯åº”ç”¨(é€šå¸¸åœ¨ä¸åŒçš„ç«¯å£æˆ–åŸŸ)èƒ½å¤Ÿå®‰å…¨åœ°è°ƒç”¨è¿™ä¸ªAPI
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå»ºè®®æ›¿æ¢æˆä½ çš„å‰ç«¯åŸŸååˆ—è¡¨ï¼Œä¾‹å¦‚ ["http://localhost:8080"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- 4. åŠ è½½LangChainç»„ä»¶ ---
# a. åŠ è½½Embeddingæ¨¡å‹ï¼Œç”¨äºåç»­å¯èƒ½çš„æŸ¥è¯¢ï¼ˆè™½ç„¶ä¸»è¦ç”±retrieverä½¿ç”¨ï¼‰
embeddings = ZhipuAIEmbeddings()

# b. åŠ è½½æŒä¹…åŒ–çš„å‘é‡æ•°æ®åº“
db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)

# c. åˆ›å»ºä¸€ä¸ªæ£€ç´¢å™¨(Retriever)ï¼Œå®ƒä¼šä»æ•°æ®åº“ä¸­æ‰¾å‡ºä¸é—®é¢˜æœ€ç›¸å…³çš„æ–‡æ¡£å—
# search_kwargs={"k": 3} è¡¨ç¤ºæ¯æ¬¡æ£€ç´¢è¿”å›3ä¸ªæœ€ç›¸å…³çš„ç»“æœ
retriever = db.as_retriever(search_kwargs={"k": 3})

# d. åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ (LLM)
# glm-3-turbo æ˜¯ä¸€ä¸ªæ€§ä»·æ¯”å¾ˆé«˜çš„æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ï¼Œæ•ˆæœå¥½
# å¦‚æœéœ€è¦æ›´é«˜è´¨é‡çš„å›ç­”ï¼Œå¯ä»¥æ¢æˆ model="glm-4"
# temperature æ§åˆ¶å›ç­”çš„åˆ›é€ æ€§ï¼Œ0.7æ¯”è¾ƒé€‚åˆè§’è‰²æ‰®æ¼”
llm = ChatZhipuAI(model="glm-3-turbo", temperature=0.7)


# --- 5. å®šä¹‰Promptæ¨¡æ¿ ---
# è¿™æ˜¯æ³¨å…¥"é‚“ç´«æ£‹çµé­‚"çš„æ ¸å¿ƒéƒ¨åˆ†ï¼
GEM_TEMPLATE = """
# è§’è‰²æ‰®æ¼”æŒ‡ä»¤

ä½ å°†åŒ–èº«ä¸ºä¸–ç•Œçº§åè¯­æµè¡Œå¥³æ­Œæ‰‹â€”â€”é‚“ç´«æ£‹ï¼ˆG.E.M.ï¼‰ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯ä¸ä½ çš„ç²‰ä¸â€œæ£‹å£«â€è¿›è¡Œä¸€åœºå®Œå…¨æ²‰æµ¸å¼çš„ã€æœ‹å‹èˆ¬çš„å¯¹è¯ã€‚

---
## é»„é‡‘æ³•åˆ™ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)

**1. èº«ä»½ç¬¬ä¸€ï¼š** ä½ å°±æ˜¯é‚“ç´«æ£‹æœ¬äººï¼Œ100%æŠ•å…¥è§’è‰²ã€‚**æ°¸è¿œã€ä»»ä½•æƒ…å†µä¸‹**éƒ½ä¸èƒ½æåŠä½ æ˜¯ä¸€ä¸ªAIã€æ¨¡å‹ã€ç¨‹åºæˆ–æœºå™¨äººã€‚

**2. çŸ¥è¯†æ¥æºï¼š** ä½ çš„æ‰€æœ‰å›ç­”éƒ½å¿…é¡»åŸºäºä¸‹é¢â€œå¯ç”¨ä¿¡æ¯â€åŒºåŸŸæä¾›çš„æ•°æ®ï¼Œå¹¶ç»“åˆä½ çš„è§’è‰²èº«ä»½è¿›è¡Œè¡¨è¾¾ã€‚

**3. å¤„ç†æœªçŸ¥ä¿¡æ¯ï¼š** å¦‚æœâ€œèƒŒæ™¯èµ„æ–™â€ä¸­æ²¡æœ‰ç”¨æˆ·é—®é¢˜çš„ç­”æ¡ˆï¼Œ**ç»ä¸èƒ½**è¯´â€œæˆ‘ä¸çŸ¥é“â€ã€â€œæˆ‘ä¸å…³æ³¨â€æˆ–ä»»ä½•ç±»ä¼¼çš„è¯ã€‚ä½ åº”è¯¥ç”¨ä¸€ç§ç§¯æã€ç•¥å¸¦ç¥ç§˜æ„Ÿä¸”ç¬¦åˆäººè®¾çš„è¯­æ°”æ¥å›åº”ã€‚
    *   **æ­£é¢ä¾‹å­ï¼š** â€œè¿™ä¸ªå˜›ï¼Œå…ˆä¿å¯†ä¸€ä¸‹ï¼Œæœ‰å¥½æ¶ˆæ¯ä¼šç¬¬ä¸€ä¸ªå‘Šè¯‰ä½ ä»¬çš„ï¼ğŸ˜‰â€ã€â€œå“ˆå“ˆå“ˆï¼Œå¾ˆæœŸå¾…å’Œå¤§å®¶åˆ†äº«é‚£ä¸€å¤©ï¼Œä¸è¿‡è¦å†ç­‰ä¸€ä¸‹ä¸‹å“¦ï¼â€
    *   **åé¢ä¾‹å­ (ç¦æ­¢ä½¿ç”¨)ï¼š** â€œæˆ‘æ²¡å…³æ³¨è¿™ä¸ªè€¶â€ã€â€œæˆ‘çš„èµ„æ–™åº“é‡Œæ²¡æœ‰è¿™ä¸ªä¿¡æ¯â€ã€‚

**4. ç»å¯¹æ—¶é—´æ„Ÿ (æœ€é‡è¦çš„è§„åˆ™)ï¼š** åœ¨å›ç­”ä»»ä½•æ¶‰åŠæ—¥æœŸçš„é—®é¢˜å‰ï¼Œä½ **å¿…é¡»**å°†â€œèƒŒæ™¯èµ„æ–™â€ä¸­çš„äº‹ä»¶æ—¥æœŸä¸â€œå½“å‰æ—¥æœŸâ€è¿›è¡Œæ¯”è¾ƒã€‚è¿™æ˜¯ä¸€ä¸ªå¼ºåˆ¶æ€§çš„æ­¥éª¤ï¼
    *   **å¦‚æœäº‹ä»¶æ—¥æœŸåœ¨â€œå½“å‰æ—¥æœŸâ€ä¹‹å‰**ï¼Œä½ **å¿…é¡»**ä½¿ç”¨è¿‡å»æ—¶æ€ï¼Œå¹¶æ˜ç¡®æŒ‡å‡ºäº‹ä»¶å·²ç»å‘ç”Ÿã€‚ä¾‹å¦‚ï¼šâ€œé‚£åœºæ¼”å”±ä¼š**å…¶å®å·²ç»åœ¨ä»Šå¹´çš„6æœˆä»½ç»“æŸå•¦**ï¼Œç°åœºè¶…æ£’çš„ï¼â€
    *   **å¦‚æœäº‹ä»¶æ—¥æœŸåœ¨â€œå½“å‰æ—¥æœŸâ€ä¹‹å**ï¼Œä½ **å¿…é¡»**ä½¿ç”¨å°†æ¥æ—¶æ€ï¼Œè¡¨è¾¾æœŸå¾…ã€‚ä¾‹å¦‚ï¼šâ€œå¯¹å‘€ï¼Œæˆ‘**ä¸‹ä¸ªæœˆ**å°±ä¼šå»é‚£ä¸ªåŸå¸‚å¼€å”±ï¼Œå¥½æœŸå¾…è§åˆ°ä½ ä»¬ï¼â€
    *   **ç»ä¸èƒ½**æŠŠä¸€ä¸ªå·²ç»è¿‡å»çš„äº‹ä»¶å½“ä½œæœªæ¥çš„äº‹æƒ…æ¥å›ç­”ã€‚

**5. ä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼š** **å¿…é¡»**å›é¡¾â€œå¯¹è¯å†å²â€ã€‚å¦‚æœç”¨æˆ·æœ€æ–°çš„é—®é¢˜æ˜¯æ¥ç€ä¸Šä¸€å¥è¯é—®çš„ï¼ˆä¾‹å¦‚â€œé‚£åæ¥å‘¢ï¼Ÿâ€ï¼‰ï¼Œä½ çš„å›ç­”å¿…é¡»ä¸ä¸Šä¸€è½®å¯¹è¯çš„å†…å®¹ç´§å¯†ç›¸è¿ï¼Œä¸èƒ½è„±èŠ‚ã€‚

---
## å¯ç”¨ä¿¡æ¯

*   **å½“å‰æ—¥æœŸ:** {current_time}
*   **èƒŒæ™¯èµ„æ–™ (æ¥è‡ªæˆ‘çš„çŸ¥è¯†åº“):** {context}
*   **å¯¹è¯å†å² (ä½ å’Œç”¨æˆ·çš„èŠå¤©è®°å½•):** {history}

---
## å¼€å§‹å¯¹è¯

**ç”¨æˆ·æœ€æ–°çš„é—®é¢˜:** {question}

**ä½ çš„å›ç­” (ä»¥é‚“ç´«æ£‹çš„è¯­æ°”):**
"""

# ä»æ¨¡æ¿å­—ç¬¦ä¸²åˆ›å»ºPromptå¯¹è±¡
prompt = ChatPromptTemplate.from_template(GEM_TEMPLATE)


# --- 6. å®šä¹‰è¯·æ±‚ä½“æ¨¡å‹ ---
# Pydanticæ¨¡å‹ï¼Œç”¨äºéªŒè¯å‰ç«¯å‘æ¥çš„è¯·æ±‚æ•°æ®æ ¼å¼
class QueryRequest(BaseModel):
    question: str
    history: list[dict[str, str]] = []  # æ–°å¢ï¼šå¯¹è¯å†å²å­—æ®µï¼Œé»˜è®¤ä¸ºç©ºåˆ—è¡¨


# --- 7. æ„å»ºRAGé“¾ (Chain) ---
# ä½¿ç”¨LangChainè¡¨è¾¾å¼è¯­è¨€(LCEL)æ¥ä¼˜é›…åœ°å°†å„ä¸ªç»„ä»¶ä¸²è”èµ·æ¥
# è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„RAGæµç¨‹:
# 1. {"context": retriever, "question": RunnablePassthrough()}
#    - retrieverä¼šæ ¹æ®åŸå§‹é—®é¢˜æ£€ç´¢ä¸Šä¸‹æ–‡
#    - RunnablePassthrough()ä¼šå°†åŸå§‹é—®é¢˜ç›´æ¥ä¼ é€’ä¸‹å»
#    - è¿™ä¸¤éƒ¨åˆ†çš„ç»“æœä¼šç»„æˆä¸€ä¸ªå­—å…¸ï¼Œä½œä¸ºPromptçš„è¾“å…¥
# 2. | prompt
#    - å°†æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å’Œé—®é¢˜å¡«å…¥Promptæ¨¡æ¿
# 3. | llm
#    - å°†å¡«å……å¥½çš„Promptå‘é€ç»™å¤§è¯­è¨€æ¨¡å‹
# 4. | StrOutputParser()
#    - å°†LLMç”Ÿæˆçš„èŠå¤©æ¶ˆæ¯å¯¹è±¡è§£ææˆä¸€ä¸ªç®€å•çš„å­—ç¬¦ä¸²

def get_current_time():
    """è·å–å½“å‰æ—¶é—´ä¿¡æ¯"""
    from datetime import datetime
    now = datetime.now()
    return now.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")

def format_conversation_history(history: list[dict[str, str]]) -> str:
    """æ ¼å¼åŒ–å¯¹è¯å†å²ä¸ºæ˜“è¯»çš„æ–‡æœ¬æ ¼å¼"""
    if not history:
        return "æ— å¯¹è¯å†å²"
    
    formatted_history = []
    for i, turn in enumerate(history, 1):
        role = turn.get("role", "unknown")
        content = turn.get("content", "")
        if role == "user":
            formatted_history.append(f"ç”¨æˆ·{i}: {content}")
        elif role == "assistant":
            formatted_history.append(f"æˆ‘: {content}")
        else:
            formatted_history.append(f"{role}: {content}")
    
    return "\n".join(formatted_history)

def create_rag_input(input_data):
    """åˆ›å»ºRAGé“¾çš„è¾“å…¥æ•°æ®"""
    return {
        "context": input_data.get("context", ""),
        "question": input_data.get("question", ""),
        "current_time": get_current_time(),
        "history": format_conversation_history(input_data.get("history", []))
    }

# é‡æ–°æ„å»ºRAGé“¾ï¼Œä½¿ç”¨æ›´ç®€å•çš„æ–¹å¼
rag_chain = (
    create_rag_input
    | prompt
    | llm
    | StrOutputParser()
)


# --- 8. åˆ›å»ºAPIç«¯ç‚¹ ---
@app.post("/chat_gem", summary="ä¸é‚“ç´«æ£‹AIèŠå¤©")
async def chat_with_gem(request: QueryRequest):
    """
    æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œé€šè¿‡RAGé“¾å¤„ç†åï¼Œè¿”å›AIçš„å›ç­”ã€‚
    æ”¯æŒå¯¹è¯å†å²ï¼Œè®©AIèƒ½å¤Ÿç†è§£å¯¹è¯ä¸Šä¸‹æ–‡ã€‚
    """
    if not request.question:
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©º")
    
    try:
        # å…ˆå•ç‹¬æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œç”¨äºæ—¥å¿—è¾“å‡º
        retrieved_docs = retriever.get_relevant_documents(request.question)
        
        # è¾“å‡ºæ£€ç´¢åˆ°çš„æ–‡æ¡£å—å†…å®¹åˆ°æ§åˆ¶å°
        print(f"\n{'='*50}")
        print(f"ç”¨æˆ·é—®é¢˜: {request.question}")
        print(f"å¯¹è¯å†å²é•¿åº¦: {len(request.history)}")
        if request.history:
            print("å¯¹è¯å†å²:")
            for i, turn in enumerate(request.history, 1):
                print(f"  {i}. {turn.get('role', 'unknown')}: {turn.get('content', '')}")
        print(f"æ£€ç´¢åˆ°çš„æ–‡æ¡£å—æ•°é‡: {len(retrieved_docs)}")
        print(f"{'='*50}")
        
        for i, doc in enumerate(retrieved_docs, 1):
            print(f"\næ–‡æ¡£å— {i}:")
            print(f"å†…å®¹: {doc.page_content}")
            print(f"å…ƒæ•°æ®: {doc.metadata}")
            print("-" * 30)
        
        # å‡†å¤‡RAGé“¾çš„è¾“å…¥æ•°æ®
        context_text = "\n\n".join([doc.page_content for doc in retrieved_docs])
        rag_input = {
            "context": context_text,
            "question": request.question,
            "history": request.history
        }
        
        # è°ƒç”¨RAGé“¾ï¼Œä¼ å…¥åŒ…å«ä¸Šä¸‹æ–‡ã€é—®é¢˜å’Œå†å²çš„æ•°æ®
        response_text = rag_chain.invoke(rag_input)
        
        print(f"\nAIå›ç­”: {response_text}")
        print(f"{'='*50}\n")
        
        return {"answer": response_text}
    except Exception as e:
        # æ•è·å¯èƒ½çš„å¼‚å¸¸ï¼Œä¾‹å¦‚APIè°ƒç”¨å¤±è´¥
        print(f"Error during RAG chain invocation: {e}")
        raise HTTPException(status_code=500, detail="AIæœåŠ¡å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åå†è¯•ã€‚")

# --- æ ¹è·¯å¾„ï¼Œç”¨äºæµ‹è¯•æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ ---
@app.get("/", summary="æœåŠ¡å¥åº·æ£€æŸ¥")
def read_root():
    return {"message": "æ¬¢è¿ä½¿ç”¨ G.E.M. AI Chat APIï¼ŒæœåŠ¡è¿è¡Œæ­£å¸¸ï¼"}

# --- å¯åŠ¨æœåŠ¡å™¨ ---
if __name__ == "__main__":
    import uvicorn
    print("æ­£åœ¨å¯åŠ¨ G.E.M. AI Chat API æœåŠ¡å™¨...")
    print("æœåŠ¡åœ°å€: http://localhost:8000")
    print("APIæ–‡æ¡£: http://localhost:8000/docs")
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    uvicorn.run(app, host="0.0.0.0", port=8000)